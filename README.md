# TF Web app 

**An object detection web app using `Tflite`(inference), `React`(frontend) and `Flask`(backend). Originally based on this [Medium article](https://medium.com/sopra-steria-norge/build-a-simple-image-classification-app-using-react-keras-and-flask-7b9075e3b6f5)).** 

**Had to switch to image uploading due to numpy buffer errors with `Interpreter` and `Flask` on Heroku.**


**Model Card** : [EfficientDet Lite3](https://tfhub.dev/tensorflow/lite-model/efficientdet/lite3/detection/default/1) A pretrained model on the COCO2017 dataset, and as can be seen, the accuracy is quite bad.

Loading spinner taken from [loading.io][3]

**v0.2 notes**:


- Got it down to 102% and less with `tflite`, however now run into `interpreter` internal buffer issues

- Have got it down to 152% with a smaller model and some `gc`

    > [web.1]: Process running mem=783M(152.2%)
    > 
    >[web.1]: Error R14 (Memory quota exceeded)

- Seem to run into memory error with Heroku
    
    >[web.1]: Process running mem=1189M(232.4%)
    >
    >[web.1]: Error R15 (Memory quota vastly exceeded)


**v0.1 notes**:


    It was even harder to get it working on Heroku, atleast its deployed now ðŸ™‚!

## Tips for deploying on Heroku
- Use `tensorflow-cpu` in the requirements - keeps slug size within limits[<sup>1</sup>][1]
  - tf2.6 has some weird bug with keras dependency, so make sure to add `keras` version to `requirements` if using
- Make sure `Procfile` and `requirements.txt` are in root folder
- Make sure you have all buildpacks specified(accesible from Settings) - in this case `heroku/python` and `heroku/nodejs`
- Remember to set the host to `0.0.0.0` and the port to `PORT` since these are both generated by heroku
- Memory usage needs to be limited to 512MB

[1]: https://stackoverflow.com/questions/61062303/deploy-python-app-to-heroku-slug-size-too-large
[2]: https://stackoverflow.com/questions/56902522/react-show-loading-spinner-while-images-load  
[3]: https://loading.io/css/